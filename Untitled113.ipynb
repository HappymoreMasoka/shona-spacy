{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuEIGTIHVSDG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Load your chat dataset (adjust file path/column name)\n",
        "df = pd.read_csv(\"shona_chats.csv\")   # assume your file\n",
        "messages = df[\"message\"].dropna().tolist()\n",
        "\n",
        "# 1. Tokenizer\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\w+\", str(text).lower())\n",
        "\n",
        "tokens = []\n",
        "for msg in messages:\n",
        "    tokens.extend(tokenize(msg))\n",
        "\n",
        "print(\"Total tokens:\", len(tokens))\n",
        "print(\"Unique tokens:\", len(set(tokens)))\n",
        "\n",
        "# 2. Count frequency\n",
        "freq = Counter(tokens)\n",
        "print(\"Top 20 words:\")\n",
        "print(freq.most_common(20))\n",
        "\n",
        "# 3. Simple prefix/suffix stripping (candidate root extraction)\n",
        "INFLECTIONAL_PREFIXES = [\"ndi\", \"va\", \"ha\", \"ta\", \"ma\", \"chi\", \"zvi\", \"ru\", \"ka\", \"tu\", \"hu\", \"ku\", \"pa\", \"mu\", \"ri\"]\n",
        "DERIVATIONAL_SUFFIXES = [\"a\", \"i\", \"e\", \"o\", \"an\", \"ana\", \"sa\", \"tu\", \"is\", \"ir\", \"er\", \"ur\", \"unur\", \"w\", \"iw\", \"irw\"]\n",
        "\n",
        "def extract_root(word):\n",
        "    root = word\n",
        "    for p in INFLECTIONAL_PREFIXES:\n",
        "        if root.startswith(p) and len(root) > len(p)+2:\n",
        "            root = root[len(p):]\n",
        "            break\n",
        "    for s in DERIVATIONAL_SUFFIXES:\n",
        "        if root.endswith(s) and len(root) > len(s)+1:\n",
        "            root = root[:-len(s)]\n",
        "            break\n",
        "    return root\n",
        "\n",
        "# Apply to most frequent words\n",
        "roots = [(w, freq[w], extract_root(w)) for w in list(freq.keys())[:500]]\n",
        "\n",
        "# 4. Save to CSV for manual annotation\n",
        "roots_df = pd.DataFrame(roots, columns=[\"word_form\", \"count\", \"candidate_root\"])\n",
        "roots_df.to_csv(\"shona_candidate_roots.csv\", index=False)\n",
        "\n",
        "print(\"Candidate roots saved to shona_candidate_roots.csv\")\n"
      ]
    }
  ]
}